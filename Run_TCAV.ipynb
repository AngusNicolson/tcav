{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v88fM4ciYYde",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Running TCAV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-RlU8wNYYdj",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This notebook walks you through an example application of the TCAV library step-by-step to understand which human interpretable concepts (e.g. stripes, dots, zigzags) are important to the image classifier GoogleNet's (a.k.a. Inception v1) prediction of Zebras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1zIj8-aYYdj",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Install required packages\n",
    "\n",
    "To run through this notebook in the interim, you are encouraged to utilize a `virtualenv` or `conda` environment for installing and working with the required packages to avoid any dependency and compatability issues with different versions of packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sIHww5CuYYdk",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%pip install tcav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NT91qkMYYdk",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Download example models and images\n",
    "\n",
    "Open a terminal and run the following commands:\n",
    "\n",
    "```\n",
    "cd tcav/tcav_examples/image_models/imagenet\n",
    "\n",
    "python download_and_make_datasets.py --source_dir=YOUR_PATH --number_of_images_per_folder=50 --number_of_random_folders=3\n",
    "```\n",
    "\n",
    "This script will download the following content into separate folders into a directory you specify with the `--source_dir=` argument:\n",
    "\n",
    "**Images**\n",
    "*  ImageNet images for the target Zebra class\n",
    "*  [Broden dataset](http://netdissect.csail.mit.edu/) images for three concepts (e.g. striped, dotted, zigzagged)\n",
    "*  Random ImageNet class images used by TCAV for hypothesis testing of important concepts\n",
    "\n",
    "**Models**\n",
    "*  [Inception 5h model](https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/inception5h.py)\n",
    "*  [Mobilenet V2 model](https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlrLUu4zYYdl",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import extensions and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sS1ZjSZjYYdl",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U4yP9kDlYYdl",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "from torchvision import models\n",
    "\n",
    "from tcav.model import ModelWrapper\n",
    "from tcav.dataset import JsonDataset\n",
    "import tcav.activation_generator as act_gen\n",
    "import tcav.cav as cav\n",
    "import tcav.tcav as tcav\n",
    "import tcav.utils as utils\n",
    "import tcav.utils_plot as utils_plot # utils_plot requires matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yitpnXmEYYdm",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## TCAV step-by-step\n",
    "\n",
    "You will walk through the following steps below:\n",
    "\n",
    "1. **Store example images in each folder** (you have this if you ran the above)\n",
    " * images for each concept\n",
    " * images for the class/labels of interest\n",
    " * random images that will be negative examples when learning CAVs (images that probably don't belong to any concepts)\n",
    "2. **Write a model wrapper** (below uses example from tcav/model.py)\n",
    " * an instance of  ModelWrapper abstract class (in model.py). This tells TCAV class (tcav.py) how to communicate with your model (e.g., getting internal tensors)\n",
    "3. **Retrieve model activations** (below uses example from tcav/activation_generator.py)\n",
    " * an instance of ActivationGeneratorInterface that tells TCAV class how to load example data and how to get activations from the model\n",
    "4. Run TCAV and visualize scores for important concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjjLK3pBYYdm",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 1: Store concept and target class images to local folders\n",
    "\n",
    "... and tell TCAV where they are.\n",
    "\n",
    "**source_dir**: where images of concepts, target class and random images (negative samples when learning CAVs) live. Each should be a sub-folder within this directory.\n",
    "\n",
    "Note that random image directories can be in any name. In this example, we are using `random500_0`, `random500_1`,.. for an arbitrary reason. \n",
    "\n",
    "You need roughly 50-200 images per concept and target class (10-20 pictures also tend to work, but 200 is pretty safe).\n",
    "\n",
    "\n",
    "**cav_dir**: directory to store CAVs (`None` if you don't want to store)\n",
    "\n",
    "**target, concept**: names of the target class (that you want to investigate) and concepts (strings) - these are folder names in source_dir\n",
    "\n",
    "**bottlenecks**: list of bottleneck names (intermediate layers in your model) that you want to use for TCAV. These names are defined in the model wrapper below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EHabMnMNYYdm",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print ('REMEMBER TO UPDATE YOUR_PATH (where images, models are)!')\n",
    "\n",
    "# This is the name of your model wrapper (InceptionV3 and GoogleNet are provided in model.py)\n",
    "model_to_run = 'ResNet50'\n",
    "user = 'angus'\n",
    "# the name of the parent directory that results are stored (only if you want to cache)\n",
    "project_name = 'tcav_zebra_test'\n",
    "#working_dir = Path(\"/tmp/\" + user + '/' + project_name)\n",
    "working_dir = Path(\"/home/lina3782/labs/explain/imagenet/output\")\n",
    "# where activations are stored (only if your act_gen_wrapper does so)\n",
    "activation_dir =  working_dir / 'activations'\n",
    "# where CAVs are stored. \n",
    "# You can say None if you don't wish to store any.\n",
    "cav_dir = working_dir / 'cavs'\n",
    "grad_dir = working_dir / \"grads\"\n",
    "# where the images live.\n",
    "\n",
    "# TODO: replace 'YOUR_PATH' with path to downloaded models and images.\n",
    "source_dir = Path('/home/lina3782/labs/explain/imagenet')\n",
    "bottlenecks = [\"layer2.1\", \"layer2.2\", \"layer2.3\", \"layer3.0\", \"layer3.1\", \"layer3.2\", \"layer3.3\", \"layer3.4\", \"layer3.5\", \"layer4.0\", 'layer4.1', \"layer4.2\"]  # @param\n",
    "bottlenecks = {bn:bn for bn in bottlenecks}\n",
    "\n",
    "for d in [activation_dir, working_dir, cav_dir, grad_dir]:\n",
    "    d.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# this is a regularizer penalty parameter for linear classifier to get CAVs. \n",
    "alphas = [0.1]   \n",
    "\n",
    "num_random_exp = 30\n",
    "target = 'zebra'\n",
    "# concepts = [\"polka\", \"flecked\", \"dotted\", \"striped\", \"lined\", \"banded\", \"zigzagged\"]\n",
    "concepts = [\"striped\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_DfQqsAYYdn",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 2: Write your model wrapper\n",
    "\n",
    "The next step is to tell TCAV how to communicate with your model. See `model.GoogleNetWrapper_public ` for details.\n",
    "\n",
    "You can define a subclass of ModelWrapper abstract class to do this. Let me walk you thru what each function does (tho they are pretty self-explanatory).  This wrapper includes a lot of the functions that you already have, for example, `get_prediction`.\n",
    "\n",
    "### 2.1: Tensors from the graph: bottleneck tensors and ends\n",
    "First, store your bottleneck tensors in `self.bottlenecks_tensors` as a dictionary. You only need bottlenecks that you are interested in running TCAV with. Similarly, fill in `self.ends` dictionary with `input`, `logit` and `prediction` tensors.\n",
    "\n",
    "### 2.2: Define loss\n",
    "Get your loss tensor, and assigned it to `self.loss`. This is what TCAV uses to take directional derivatives. \n",
    "\n",
    "While doing so, you would also want to set \n",
    "```python\n",
    "self.y_input \n",
    "```\n",
    "this simply is a tensorflow place holder for the target index in the logit layer (e.g., 0 index for a dog, 1 for a cat).\n",
    "For multi-class classification, typically something like this works:\n",
    "\n",
    "```python\n",
    "self.y_input = tf.placeholder(tf.int64, shape=[None])\n",
    "```\n",
    "\n",
    "For example, for a multiclass classifier, something like below would work. \n",
    "\n",
    "```python\n",
    "    # Construct gradient ops.\n",
    "    with g.as_default():\n",
    "      self.y_input = tf.placeholder(tf.int64, shape=[None])\n",
    "\n",
    "      self.pred = tf.expand_dims(self.ends['prediction'][0], 0)\n",
    "\n",
    "      self.loss = tf.reduce_mean(\n",
    "          tf.nn.softmax_cross_entropy_with_logits(\n",
    "              labels=tf.one_hot(self.y_input, len(self.labels)),\n",
    "              logits=self.pred))\n",
    "    self._make_gradient_tensors()\n",
    "```\n",
    "\n",
    "### 2.3: Call _make_gradient_tensors in __init__() of your wrapper\n",
    "```python\n",
    "_make_gradient_tensors()  \n",
    "```\n",
    "does what you expect - given the loss and bottleneck tensors defined above, it adds gradient tensors.\n",
    "\n",
    "### 2.4: Fill in labels, image shapes and a model name.\n",
    "Get the mapping from labels (strings) to indice in the logit layer (int) in a dictionary format.\n",
    "\n",
    "```python\n",
    "def id_to_label(self, idx)\n",
    "def label_to_id(self, label)\n",
    "```\n",
    "\n",
    "Set your input image shape at  `self.image_shape`\n",
    "\n",
    "\n",
    "Set your model name to `self.model_name`\n",
    "\n",
    "You are done with writing the model wrapper! See the two example model wrapers, InceptionV3 and Googlenet in `tcav/model.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    return models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hH-YQiEIYYdn",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# model_path is where the trained model is stored.\n",
    "#model_path = source_dir / \"/inception5h/example_model.pt\"\n",
    "model = create_model()\n",
    "#model = model.load_state(model_path)\n",
    "\n",
    "# LABEL_PATH is where the labels are stored. Each line contains one class, and they are ordered with respect to their index in \n",
    "# the logit layer. (yes, id_to_label function in the model wrapper reads from this file.)\n",
    "# For example, imagenet_comp_graph_label_strings.txt looks like:\n",
    "# dummy                                                                                      \n",
    "# kit fox\n",
    "# English setter\n",
    "# Siberian husky ...\n",
    "label_path = source_dir / \"class_names.txt\"\n",
    "with open(label_path, \"r\") as fp:\n",
    "    class_names = fp.read()\n",
    "class_names = class_names.split(\"\\n\")\n",
    "class_names_short = [v.split(\",\")[0] for v in class_names]\n",
    "mymodel = ModelWrapper(model, bottlenecks, class_names_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class_names_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mymodel.label_to_id(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yY5kXbVAYYdo",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 3: Implement a class that returns activations (maybe with caching!)\n",
    "\n",
    "Lastly, you will implement a class of the ActivationGenerationInterface which TCAV uses to load example data for a given concept or target, call into your model wrapper and return activations. I pulled out this logic outside of mymodel because this step often takes the longest. By making it modular, you can cache your activations and/or parallelize your computations, as I have done in `ActivationGeneratorBase.process_and_load_activations` in `activation_generator.py`.\n",
    "\n",
    "\n",
    "The `process_and_load_activations` method of the activation generator must return a dictionary of activations that has concept or target name as  a first key, and the bottleneck name as a second key. So something like:\n",
    "\n",
    "```python\n",
    "{concept1: {bottleneck1: [[0.2, 0.1, ....]]},\n",
    "concept2: {bottleneck1: [[0.1, 0.02, ....]]},\n",
    "target1: {bottleneck1: [[0.02, 0.99, ....]]}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_path = source_dir / \"data\"\n",
    "\n",
    "source_json = {}\n",
    "for concept in [target] + concepts + [f\"random500_{i}\" for i in range(num_random_exp)]:\n",
    "    paths = (data_path / concept).glob(\"*.jpg\")\n",
    "    source_json[concept] = {i: {\"path\": f\"{concept}/{path.name}\", \"label\": 0} for i, path in enumerate(paths)}\n",
    "\n",
    "source_json_path = source_dir / \"example_source_json.json\"\n",
    "with open(source_json_path, \"w\") as fp:\n",
    "    json.dump(source_json, fp, indent=2)\n",
    "\n",
    "source_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "concept_dict = {\n",
    "    \"concept1\": {\"0\": {\"path\": \"dasd\", \"label\": \"asd\"}, \"1\": {}},\n",
    "    \"concept2\": {},\n",
    "    \"random500_0\": {},\n",
    "    \"random500_1\": {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZmSyFxQbYYdo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_examples = 100\n",
    "prefix = str(data_path) + \"/\"\n",
    "num_workers = 4\n",
    "\n",
    "act_generator = act_gen.ActivationGenerator(mymodel, source_json_path, activation_dir, JsonDataset, max_examples=max_examples, prefix=prefix, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "example_dataset = JsonDataset(source_json, target, prefix)\n",
    "example_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uABCWhp8YYdo",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 4: Run TCAV and visualize concept importance\n",
    "\n",
    "You are now ready to run TCAV! Let's do it.\n",
    "\n",
    "**num_random_exp**: number of experiments to confirm meaningful concept direction. TCAV will search for this many folders named `random500_0`, `random500_1`, etc. You can alternatively set the `random_concepts` keyword to be a list of folders of random concepts. Run at least 10-20 for meaningful tests. \n",
    "\n",
    "**random_counterpart**: as well as the above, you can optionally supply a single folder with random images as the \"positive set\" for statistical testing. Reduces computation time at the cost of less reliable random TCAV scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F2FVOGSvYYdp",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## only running num_random_exp = 10 to save some time. The paper number are reported for 500 random runs.\n",
    "\n",
    "mytcav = tcav.TCAV(\n",
    "    target,\n",
    "    concepts,\n",
    "    bottlenecks,\n",
    "    act_generator,\n",
    "    alphas,\n",
    "    cav_dir=cav_dir,\n",
    "    num_random_exp=num_random_exp,\n",
    "    do_random_pairs=True,\n",
    "    grad_dir=grad_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Training CAVs...\")\n",
    "mytcav.train_cavs(overwrite=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print ('This may take a while... Go get coffee!')\n",
    "results = mytcav.run(overwrite=False)\n",
    "print ('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = utils_plot.plot_results(results, num_random_exp=num_random_exp, figsize=(10, 5))\n",
    "fig.axes[0].axhline(0.5, color=\"gray\", alpha=0.8, linestyle=\"--\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results_dir = source_dir / f\"results/{target}\"\n",
    "results_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp_name = \"21-22-33-34-35-40-41-42_100.json\"\n",
    "with open(results_dir / f\"{exp_name}.json\", \"w\") as fp:\n",
    "    json.dump(results, fp, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp_name = \"21-22-33-34-35-40-41-42_100.json\"\n",
    "with open(results_dir / f\"{exp_name}.json\", \"r\") as fp:\n",
    "    results = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "target = \"zebra\"\n",
    "source_json = {}\n",
    "for concept in [target] + concepts + [f\"random500_{i}\" for i in range(num_random_exp)]:\n",
    "    paths = (data_path / concept).glob(\"*.jpg\")\n",
    "    source_json[concept] = {i: {\"path\": f\"{concept}/{path.name}\", \"label\": 0} for i, path in enumerate(paths)}\n",
    "\n",
    "source_json_path = source_dir / \"example_source_json.json\"\n",
    "with open(source_json_path, \"w\") as fp:\n",
    "    json.dump(source_json, fp, indent=2)\n",
    "\n",
    "act_generator = act_gen.ActivationGenerator(mymodel, source_json_path, activation_dir, JsonDataset, max_examples=max_examples, prefix=prefix, num_workers=4)\n",
    "\n",
    "mytcav = tcav.TCAV(\n",
    "    target,\n",
    "    concepts,\n",
    "    bottlenecks,\n",
    "    act_generator,\n",
    "    alphas,\n",
    "    cav_dir=cav_dir,\n",
    "    num_random_exp=num_random_exp,\n",
    "    do_random_pairs=True,\n",
    "    grad_dir=grad_dir\n",
    ")\n",
    "results = mytcav.run(overwrite=False)\n",
    "fig = utils_plot.plot_results(results, num_random_exp=num_random_exp, figsize=(10, 5))\n",
    "fig.axes[0].axhline(0.5, color=\"gray\", alpha=0.8, linestyle=\"--\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_cols = 7\n",
    "num_rows = 2\n",
    "\n",
    "num_img = num_rows * num_cols\n",
    "\n",
    "\n",
    "for concept in concepts:\n",
    "    print(concept)\n",
    "    paths = [v[\"path\"] for v in source_json[concept].values()]\n",
    "    paths.sort()\n",
    "    idx = np.random.choice(range(len(paths)), num_img, replace=False)\n",
    "    paths = [data_path / paths[i] for i in idx]\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(2*num_cols, 2*num_rows))\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        img = Image.open(paths[i])\n",
    "        img = np.array(img)\n",
    "        ax.imshow(img)\n",
    "        ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_acc_means = {}\n",
    "all_acc_stds = {}\n",
    "for concept in concepts:\n",
    "    accs = {}\n",
    "    for bn in bottlenecks.keys():\n",
    "        accs[bn] = [v[\"cav_accuracies\"][\"overall\"] for v in results if\n",
    "                    (v[\"bottleneck\"] == bn) and (v[\"cav_concept\"] == concept)]\n",
    "    accs = np.array(list(accs.values()))\n",
    "    accs_mean = accs.mean(axis=1)\n",
    "    accs_std = accs.std(axis=1)\n",
    "\n",
    "    all_acc_means[concept] = accs_mean\n",
    "    all_acc_stds[concept] = accs_std\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for concept in concepts:\n",
    "    ax.plot(list(bottlenecks.keys()), all_acc_means[concept], label=concept)\n",
    "ax.set_xlabel(\"Layer\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "name": "Run TCAV.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}